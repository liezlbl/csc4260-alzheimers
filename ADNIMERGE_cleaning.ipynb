{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ADNIMERGE Data Cleaning\n",
        "\n",
        "* encode values: any string values need to be **hot encoded,** and numeric values need to be **normalized**\n",
        "\n",
        "\n",
        "### Columns We're Choosing To ignore:\n",
        "* colprot -- because it is the protocol under which the data is collected\n",
        "* origprot -- original protocol the subject entered the study under\n",
        "* ptid -- keeping to identify the patient as long as possible, then throwing out during actual training\n",
        "* viscode -- the visit code\n",
        "* SITE\n",
        "* fieldstreng and FLDSTRENG_bl -- 1.5 or 3 Tesla MRI strength -- ignoring for now\n",
        "* FSVERSION and FSVERSION_bl -- something about FreeSurver Version 4.3, 5.1, or 6.0 -- ignore\n",
        "* update_stamp -- a datetime object"
      ],
      "metadata": {
        "id": "dgK2Ze7LG-kC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwMJ65TtGu48"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "full_df = pd.read_csv(\"/content/drive/MyDrive/Data_Science_Alzheimers_ADNI/ADNIMERGE_08Feb2024.csv\")\n",
        "\n",
        "# select the baseline entries for each patient (yields 2430 patients)\n",
        "baseline_df = full_df[full_df['VISCODE'] == 'bl']\n",
        "\n",
        "# make a copy of the baseline_df (to avoid View vs copy issues)\n",
        "baseline_df_cleaned = baseline_df.copy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjyX5hy4HEeT",
        "outputId": "4a8d7087-8bdb-4931-c674-761ae24f95a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-d6a9f224c94b>:2: DtypeWarning: Columns (19,20,21,50,51,104,105,106) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  full_df = pd.read_csv(\"/content/drive/MyDrive/Data_Science_Alzheimers_ADNI/ADNIMERGE_08Feb2024.csv\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print column labels nicely\n",
        "i = 1\n",
        "for col in sorted(full_df.columns):\n",
        "  print(col, end=\"  \")\n",
        "  if i % 7 == 0:\n",
        "    print('')\n",
        "  i = i+1"
      ],
      "metadata": {
        "id": "lmKzU1jgI4WL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f270a7-17de-477b-daac-2f40b08ed1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ABETA  ABETA_bl  ADAS11  ADAS11_bl  ADAS13  ADAS13_bl  ADASQ4  \n",
            "ADASQ4_bl  AGE  APOE4  AV45  AV45_bl  CDRSB  CDRSB_bl  \n",
            "COLPROT  DIGITSCOR  DIGITSCOR_bl  DX  DX_bl  EXAMDATE  EXAMDATE_bl  \n",
            "EcogPtDivatt  EcogPtDivatt_bl  EcogPtLang  EcogPtLang_bl  EcogPtMem  EcogPtMem_bl  EcogPtOrgan  \n",
            "EcogPtOrgan_bl  EcogPtPlan  EcogPtPlan_bl  EcogPtTotal  EcogPtTotal_bl  EcogPtVisspat  EcogPtVisspat_bl  \n",
            "EcogSPDivatt  EcogSPDivatt_bl  EcogSPLang  EcogSPLang_bl  EcogSPMem  EcogSPMem_bl  EcogSPOrgan  \n",
            "EcogSPOrgan_bl  EcogSPPlan  EcogSPPlan_bl  EcogSPTotal  EcogSPTotal_bl  EcogSPVisspat  EcogSPVisspat_bl  \n",
            "Entorhinal  Entorhinal_bl  FAQ  FAQ_bl  FBB  FBB_bl  FDG  \n",
            "FDG_bl  FLDSTRENG  FLDSTRENG_bl  FSVERSION  FSVERSION_bl  Fusiform  Fusiform_bl  \n",
            "Hippocampus  Hippocampus_bl  ICV  ICV_bl  IMAGEUID  IMAGEUID_bl  LDELTOTAL  \n",
            "LDELTOTAL_BL  M  MMSE  MMSE_bl  MOCA  MOCA_bl  MidTemp  \n",
            "MidTemp_bl  Month  Month_bl  ORIGPROT  PIB  PIB_bl  PTAU  \n",
            "PTAU_bl  PTEDUCAT  PTETHCAT  PTGENDER  PTID  PTMARRY  PTRACCAT  \n",
            "RAVLT_forgetting  RAVLT_forgetting_bl  RAVLT_immediate  RAVLT_immediate_bl  RAVLT_learning  RAVLT_learning_bl  RAVLT_perc_forgetting  \n",
            "RAVLT_perc_forgetting_bl  RID  SITE  TAU  TAU_bl  TRABSCOR  TRABSCOR_bl  \n",
            "VISCODE  Ventricles  Ventricles_bl  WholeBrain  WholeBrain_bl  Years_bl  mPACCdigit  \n",
            "mPACCdigit_bl  mPACCtrailsB  mPACCtrailsB_bl  update_stamp  "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Alligators Function\n",
        "def remove_alligators(val):\n",
        "  if(isinstance(val, float)):\n",
        "    # no problem return\n",
        "    return val\n",
        "\n",
        "  # try to replace the alligators\n",
        "  val = val.replace('>','')\n",
        "  val = val.replace('<','')\n",
        "\n",
        "  return val\n",
        "\n",
        "# normalize Function\n",
        "def basic_normalize(col_name):\n",
        "  # get mean\n",
        "  mean = baseline_df_cleaned[col_name].mean()\n",
        "\n",
        "  # fill missing with mean\n",
        "  baseline_df_cleaned[col_name].fillna(value=mean, inplace=True)\n",
        "\n",
        "  # normalize\n",
        "  abs_max = abs(baseline_df_cleaned[col_name].max())\n",
        "  baseline_df_cleaned[col_name] = baseline_df_cleaned[col_name] / abs_max\n",
        "\n",
        "# Hot Encode Function\n",
        "def hot_encode(categories):\n",
        "  my_dict = {}\n",
        "\n",
        "  i=0\n",
        "  for c in categories:\n",
        "    my_dict[c] = i\n",
        "    i = i+1\n",
        "\n",
        "  return my_dict"
      ],
      "metadata": {
        "id": "dgSaEJNRH9aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the 'ABETA' column which has numeric data with some problem values like >1700\n",
        "\n",
        "baseline_df_cleaned['ABETA'] = baseline_df['ABETA'].apply(remove_alligators)\n",
        "\n",
        "# try to cast the column to float\n",
        "baseline_df_cleaned['ABETA'] = baseline_df_cleaned['ABETA'].astype(np.float64)\n",
        "\n",
        "# calculate the mean\n",
        "abeta_mean = baseline_df_cleaned['ABETA'].mean()\n",
        "\n",
        "# replace nan with the mean\n",
        "baseline_df_cleaned['ABETA'].fillna(value=abeta_mean, inplace=True)\n",
        "\n",
        "# normalize\n",
        "print(\"Before Normalization\")\n",
        "print(baseline_df_cleaned['ABETA'].describe())\n",
        "\n",
        "abs_max = abs(baseline_df_cleaned['ABETA'].max())\n",
        "\n",
        "baseline_df_cleaned['ABETA'] = baseline_df_cleaned.ABETA / abs_max\n",
        "\n",
        "print(\"After Normalization\")\n",
        "print(baseline_df_cleaned['ABETA'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3141tg_PIBor",
        "outputId": "23d3f644-6500-4299-cddd-21984ae8567e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Normalization\n",
            "count    2430.000000\n",
            "mean      979.928642\n",
            "std       323.299213\n",
            "min       200.000000\n",
            "25%       854.200000\n",
            "50%       979.928642\n",
            "75%       979.928642\n",
            "max      1700.000000\n",
            "Name: ABETA, dtype: float64\n",
            "After Normalization\n",
            "count    2430.000000\n",
            "mean        0.576429\n",
            "std         0.190176\n",
            "min         0.117647\n",
            "25%         0.502471\n",
            "50%         0.576429\n",
            "75%         0.576429\n",
            "max         1.000000\n",
            "Name: ABETA, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clean ABETA_bl column\n",
        "baseline_df_cleaned['ABETA_bl'] = baseline_df['ABETA_bl'].apply(remove_alligators)\n",
        "\n",
        "# try to cast the column to float\n",
        "baseline_df_cleaned['ABETA_bl'] = baseline_df_cleaned['ABETA_bl'].astype(np.float64)\n",
        "\n",
        "# calculate the mean\n",
        "abeta_mean = baseline_df_cleaned['ABETA_bl'].mean()\n",
        "\n",
        "# replace nan with the mean\n",
        "baseline_df_cleaned['ABETA_bl'].fillna(value=abeta_mean, inplace=True)\n",
        "\n",
        "# normalize\n",
        "abs_max = abs(baseline_df_cleaned['ABETA_bl'].max())\n",
        "baseline_df_cleaned['ABETA_bl'] = baseline_df_cleaned.ABETA_bl / abs_max\n"
      ],
      "metadata": {
        "id": "_pZ4nF1YIDnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean 'TAU' column (problem like >1300)\n",
        "\n",
        "baseline_df_cleaned['TAU'] = baseline_df['TAU'].apply(remove_alligators)\n",
        "\n",
        "# try to cast the column to float\n",
        "baseline_df_cleaned['TAU'] = baseline_df_cleaned['TAU'].astype(np.float64)\n",
        "\n",
        "# get the mean\n",
        "tau_mean = baseline_df_cleaned['TAU'].mean()\n",
        "\n",
        "# replace nan with mean\n",
        "baseline_df_cleaned['TAU'].fillna(value=tau_mean, inplace=True)\n",
        "\n",
        "# normalize\n",
        "abs_max = abs(baseline_df_cleaned['TAU'].max())\n",
        "baseline_df_cleaned['TAU'] = baseline_df_cleaned.TAU / abs_max"
      ],
      "metadata": {
        "id": "_oIahiAhIFpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean TAU_bl column\n",
        "\n",
        "baseline_df_cleaned['TAU_bl'] = baseline_df['TAU_bl'].apply(remove_alligators)\n",
        "\n",
        "# try to cast the column to float\n",
        "baseline_df_cleaned['TAU_bl'] = baseline_df_cleaned['TAU_bl'].astype(np.float64)\n",
        "\n",
        "# get the mean\n",
        "tau_mean = baseline_df_cleaned['TAU_bl'].mean()\n",
        "\n",
        "# replace nan with mean\n",
        "baseline_df_cleaned['TAU_bl'].fillna(value=tau_mean, inplace=True)\n",
        "\n",
        "# normalize\n",
        "abs_max = abs(baseline_df_cleaned['TAU_bl'].max())\n",
        "baseline_df_cleaned['TAU_bl'] = baseline_df_cleaned.TAU_bl / abs_max"
      ],
      "metadata": {
        "id": "iDK4AhAzIKVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean PTAU column\n",
        "baseline_df_cleaned['PTAU'] = baseline_df['PTAU'].apply(remove_alligators)\n",
        "\n",
        "# cast as float\n",
        "baseline_df_cleaned['PTAU'] = baseline_df_cleaned['PTAU'].astype(np.float64)\n",
        "\n",
        "#get mean\n",
        "ptau_mean = baseline_df_cleaned['PTAU'].mean()\n",
        "\n",
        "# replace nan with mean\n",
        "baseline_df_cleaned['PTAU'].fillna(value=ptau_mean, inplace=True)\n",
        "\n",
        "# normalize\n",
        "abs_max = abs(baseline_df_cleaned['PTAU'].max())\n",
        "baseline_df_cleaned['PTAU'] = baseline_df_cleaned.PTAU / abs_max"
      ],
      "metadata": {
        "id": "FxYUQlRlIMiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean PTAU_bl column\n",
        "baseline_df_cleaned['PTAU_bl'] = baseline_df['PTAU_bl'].apply(remove_alligators)\n",
        "\n",
        "# cast as float\n",
        "baseline_df_cleaned['PTAU_bl'] = baseline_df_cleaned['PTAU_bl'].astype(np.float64)\n",
        "\n",
        "#get mean\n",
        "ptau_mean = baseline_df_cleaned['PTAU_bl'].mean()\n",
        "\n",
        "# replace nan with mean\n",
        "baseline_df_cleaned['PTAU_bl'].fillna(value=ptau_mean, inplace=True)\n",
        "\n",
        "# normalize\n",
        "abs_max = abs(baseline_df_cleaned['PTAU_bl'].max())\n",
        "baseline_df_cleaned['PTAU_bl'] = baseline_df_cleaned.PTAU_bl / abs_max"
      ],
      "metadata": {
        "id": "APEUOJPwIOp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hot Encode Patient Gender\n",
        "categories = baseline_df_cleaned['PTGENDER'].unique()\n",
        "my_dict = hot_encode(categories)\n",
        "\n",
        "baseline_df_cleaned['PTGENDER'] = baseline_df_cleaned['PTGENDER'].replace(my_dict)\n",
        "\n",
        "baseline_df_cleaned['PTGENDER'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqKW0XL5IdDA",
        "outputId": "6fcc8749-7e23-4a4c-dbe1-0e5a10174554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize patient education\n",
        "print(\"Before:\", baseline_df_cleaned['PTEDUCAT'].unique())\n",
        "basic_normalize('PTEDUCAT')\n",
        "print(\"After:\", baseline_df_cleaned['PTEDUCAT'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us66417zIdbC",
        "outputId": "ee43a679-7095-4be5-b789-2082e66a4ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: [16 18 10 13 12  9 14 17 20 19 15  8  6  7 11  4]\n",
            "After: [0.8  0.9  0.5  0.65 0.6  0.45 0.7  0.85 1.   0.95 0.75 0.4  0.3  0.35\n",
            " 0.55 0.2 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hot encode ethnicity\n",
        "categories = baseline_df_cleaned['PTETHCAT'].unique()\n",
        "my_dict = hot_encode(categories)\n",
        "\n",
        "baseline_df_cleaned['PTETHCAT'] = baseline_df_cleaned['PTETHCAT'].replace(my_dict)\n",
        "\n",
        "baseline_df_cleaned['PTETHCAT'].unique()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFPhHzGuIfQL",
        "outputId": "7881e5c2-7c6f-4410-8367-1a1e084febb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hot encode race\n",
        "categories = baseline_df_cleaned['PTRACCAT'].unique()\n",
        "my_dict = hot_encode(categories)\n",
        "\n",
        "baseline_df_cleaned['PTRACCAT'] = baseline_df_cleaned['PTRACCAT'].replace(my_dict)\n",
        "\n",
        "baseline_df_cleaned['PTRACCAT'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTk8glVyIhJH",
        "outputId": "3071a07a-a244-423e-d3e1-a574a4ee336d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hot encode marital status at baseline\n",
        "categories = baseline_df_cleaned['PTMARRY'].unique()\n",
        "my_dict = hot_encode(categories)\n",
        "\n",
        "baseline_df_cleaned['PTMARRY'] = baseline_df_cleaned['PTMARRY'].replace(my_dict)\n",
        "\n",
        "baseline_df_cleaned['PTMARRY'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Jl6R5DyIiv6",
        "outputId": "69c5e16b-a18d-4463-dd82-1642c731a150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 2., 3., 4., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# APOE4 (Apolipoprotein E4) Genotype has nan values.\n",
        "# ASSUME: fill with zero\n",
        "baseline_df_cleaned['APOE4'] = baseline_df_cleaned['APOE4'].replace(np.nan, 0)\n"
      ],
      "metadata": {
        "id": "TdmXOs9GIlqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean FDG (average FDG-PET of angular, temporal and posterior cingulate)\n",
        "# ASSUME: fill with zero\n",
        "baseline_df_cleaned['FDG'] = baseline_df_cleaned['FDG'].replace(np.nan, 0)"
      ],
      "metadata": {
        "id": "ytkQ6ULRIncI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean PIB (average PIB SUVR of frontal cortex, anterior cingulate, precuneus cortex, and parietal cortex)\n",
        "# ASSUME: fill with zero\n",
        "baseline_df_cleaned['PIB'].unique()\n",
        "baseline_df_cleaned['PIB'] = baseline_df_cleaned['PIB'].replace(np.nan, 0)"
      ],
      "metadata": {
        "id": "xQtHsIBwIo6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean AV45 (Average AV45 SUVR of frontal, anterior cingulate, precuneus, and parietal cortex relative to the cerebellum)\n",
        "baseline_df_cleaned['AV45'].unique()\n",
        "baseline_df_cleaned['AV45'] = baseline_df_cleaned['AV45'].replace(np.nan,0)"
      ],
      "metadata": {
        "id": "k6JBkSl-IpXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CDRSB (no cleaning needed)\n",
        "baseline_df_cleaned['CDRSB'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6vyQc7qIse7",
        "outputId": "1bc935f5-15ec-4f3a-9db3-db093c8e5313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0. ,  4.5,  1. ,  0.5,  6. ,  5. ,  4. ,  2.5,  1.5,  2. ,  3. ,\n",
              "        8. ,  3.5,  7. ,  6.5,  5.5,  9. , 10. ])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAS11 Normalize\n",
        "print(\"Before:\", baseline_df_cleaned['ADAS11'].unique())\n",
        "basic_normalize('ADAS11')\n",
        "print(\"After:\", baseline_df_cleaned['ADAS11'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pN_pyKAIuDr",
        "outputId": "64c51f02-1c9b-44ee-f14f-149087d24e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: [10.67 22.   14.33  8.67 18.67 27.33 12.33  4.33  7.   10.33  6.67  4.\n",
            " 10.   21.33  6.   11.33  8.33  3.   15.33  8.    9.67 18.33 20.33 15.67\n",
            "  4.67 14.    5.67  2.    5.33 14.67 19.   18.    1.67 24.67  2.67 16.\n",
            " 22.67 26.67 13.   11.67 12.67  9.33  5.   20.67  7.33 34.33 15.   12.\n",
            " 16.33 13.67 23.   24.    6.33 13.33 28.    0.    9.    7.67  2.33 16.67\n",
            "  3.67 19.67  1.33  3.33 17.   19.33 25.33 17.67 21.67 21.   23.33 11.\n",
            "  1.   29.33 17.33 23.67 27.67 26.   22.33 20.   35.   25.67 25.   30.33\n",
            " 37.   34.67 36.   35.33 33.   29.   27.   30.   40.   38.   31.     nan\n",
            " 32.   32.33  0.67 42.67 28.33 24.33 26.33 33.33 30.67 28.67 36.33]\n",
            "After: [0.25005859 0.51558472 0.33583314 0.20318725 0.43754394 0.64049684\n",
            " 0.2889618  0.10147645 0.16404968 0.24209046 0.15631591 0.09374268\n",
            " 0.23435669 0.49988282 0.14061401 0.26552613 0.19521912 0.07030701\n",
            " 0.35926881 0.18748535 0.22662292 0.42957581 0.47644715 0.36723693\n",
            " 0.10944457 0.32809937 0.13288024 0.04687134 0.12491212 0.34380127\n",
            " 0.44527771 0.42184204 0.03913757 0.57815796 0.06257324 0.37497071\n",
            " 0.53128662 0.62502929 0.3046637  0.27349426 0.29692993 0.21865479\n",
            " 0.11717835 0.48441528 0.17178345 0.80454652 0.35153504 0.28122803\n",
            " 0.38270448 0.3203656  0.53902039 0.56245606 0.14834779 0.31239747\n",
            " 0.65619873 0.         0.21092102 0.17975158 0.05460511 0.3906726\n",
            " 0.08600891 0.46097961 0.03116944 0.07804078 0.39840637 0.45301148\n",
            " 0.5936255  0.41410827 0.50785095 0.49214905 0.54675416 0.25779236\n",
            " 0.02343567 0.68736817 0.40614015 0.55472229 0.64846496 0.6093274\n",
            " 0.52331849 0.46871338 0.82024842 0.60159363 0.58589173 0.71080384\n",
            " 0.86711976 0.81251465 0.84368409 0.82798219 0.77337708 0.6796344\n",
            " 0.63276307 0.70307007 0.93742676 0.89055543 0.72650574 0.23666041\n",
            " 0.74994141 0.75767518 0.0157019  1.         0.66393251 0.57018983\n",
            " 0.61706117 0.78111085 0.71877197 0.67190063 0.85141786]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAS13 Normalize\n",
        "print(\"Before:\", baseline_df_cleaned['ADAS13'].unique())\n",
        "basic_normalize('ADAS13')\n",
        "print(\"After:\", baseline_df_cleaned['ADAS13'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ncGSASPIvsz",
        "outputId": "8c50d3ac-e520-4aa2-fb06-bd7a59f362a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: [18.67 31.   21.33 14.67 25.67 40.33 24.33  8.33  9.   14.33  9.67  8.\n",
            " 15.   34.33 16.33 12.33 12.    5.    7.   10.   23.33 11.   17.67 28.33\n",
            " 32.33  3.   19.67 19.    4.   15.33  6.    9.33 24.67 27.   21.   28.\n",
            " 23.    1.67 28.67 36.67  3.67 26.    5.33 20.33 38.67  2.67 26.67 16.\n",
            " 21.67 13.33 16.67 31.67 22.33 17.33 49.33  8.67 24.   18.33  6.67 20.\n",
            " 22.67 33.   15.67 10.67 19.33 35.   10.33 12.67 36.    1.   11.67 14.\n",
            "  4.33 11.33 20.67  4.67 34.   29.67  3.33 22.   30.67 25.33 23.67 13.\n",
            "  7.33  5.67 27.33 36.33 29.   18.   13.67 34.67   nan  7.67 30.   26.33\n",
            " 25.   43.33 29.33 35.67 30.33 39.67 38.    2.   27.67 17.   31.33 33.67\n",
            " 35.33 32.    6.33 47.   42.   37.67 40.   33.33 40.67 42.33 41.   49.\n",
            " 47.67 50.   45.33 37.   46.   51.   39.   45.   48.   43.    0.   32.67\n",
            " 50.33 52.    0.67 54.67  1.33  2.33 41.33 41.67 38.33 47.33 44.67 42.67\n",
            " 48.33]\n",
            "After: [0.34150357 0.5670386  0.39015914 0.2683373  0.46954454 0.73769892\n",
            " 0.44503384 0.15236876 0.16462411 0.26211816 0.17687946 0.14633254\n",
            " 0.27437351 0.62794952 0.2987013  0.22553503 0.21949881 0.09145784\n",
            " 0.12804097 0.18291568 0.42674227 0.20120724 0.323212   0.51820011\n",
            " 0.59136638 0.0548747  0.35979513 0.34753978 0.07316627 0.28040973\n",
            " 0.10974941 0.17066033 0.45125297 0.49387232 0.38412292 0.51216389\n",
            " 0.42070605 0.03054692 0.52441924 0.67075178 0.06713005 0.47558076\n",
            " 0.09749406 0.37186757 0.70733492 0.04883849 0.48783611 0.29266508\n",
            " 0.39637827 0.2438266  0.30492043 0.57929395 0.4084507  0.31699287\n",
            " 0.90232303 0.15858789 0.43899762 0.33528443 0.12200476 0.36583135\n",
            " 0.41466984 0.60362173 0.28662886 0.19517103 0.353576   0.64020487\n",
            " 0.18895189 0.23175416 0.65849643 0.01829157 0.21346259 0.25608195\n",
            " 0.07920249 0.20724346 0.3780867  0.08542162 0.6219133  0.54271081\n",
            " 0.06091092 0.40241449 0.56100238 0.46332541 0.4329614  0.23779038\n",
            " 0.13407719 0.10371319 0.49990854 0.66453265 0.53045546 0.32924822\n",
            " 0.25004573 0.63416865 0.2895613  0.14029632 0.54874703 0.48161697\n",
            " 0.45728919 0.79257362 0.53649168 0.65246022 0.55478324 0.72562649\n",
            " 0.69507957 0.03658314 0.50612768 0.31095665 0.57307481 0.61587708\n",
            " 0.64624108 0.58533016 0.11578562 0.85970368 0.76824584 0.68904335\n",
            " 0.7316627  0.60965795 0.74391805 0.77428206 0.74995427 0.89628681\n",
            " 0.87195903 0.91457838 0.82915676 0.676788   0.84141211 0.93286995\n",
            " 0.71337114 0.82312054 0.87799524 0.78653741 0.         0.59758551\n",
            " 0.9206146  0.95116151 0.01225535 1.         0.02432778 0.04261935\n",
            " 0.75599049 0.76220962 0.70111579 0.86573989 0.81708432 0.78050119\n",
            " 0.88403146]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MMSE normalize\n",
        "print(\"Before:\", baseline_df_cleaned['MMSE'].unique())\n",
        "basic_normalize('MMSE')\n",
        "print(\"After:\", baseline_df_cleaned['MMSE'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAUaa4XRIxJa",
        "outputId": "d8f4f387-de66-4ec5-b2e7-2cc78089f898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: [28. 20. 27. 29. 25. 24. 30. 26. 21. 23. 22. 19. 18. 16. 17. nan]\n",
            "After: [0.93333333 0.66666667 0.9        0.96666667 0.83333333 0.8\n",
            " 1.         0.86666667 0.7        0.76666667 0.73333333 0.63333333\n",
            " 0.6        0.53333333 0.56666667 0.91269384]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RAVLT (forgetting) normalize\n",
        "print(\"Before:\", baseline_df_cleaned['RAVLT_forgetting'].unique())\n",
        "basic_normalize('RAVLT_forgetting')\n",
        "print(\"After:\", baseline_df_cleaned['RAVLT_forgetting'].unique())"
      ],
      "metadata": {
        "id": "ZplDtfOgIxiG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5609c2f7-6994-40a3-e3e8-4f974241c554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: [  6.   4.   5.   3.   1.   7.   2.   8.   0.  -1.  -5.  -2.   9.  12.\n",
            "  10.  13.  nan  11.  15.  -3.  -4.  14. -19.]\n",
            "After: [ 0.4         0.26666667  0.33333333  0.2         0.06666667  0.46666667\n",
            "  0.13333333  0.53333333  0.         -0.06666667 -0.33333333 -0.13333333\n",
            "  0.6         0.8         0.66666667  0.86666667  0.28637993  0.73333333\n",
            "  1.         -0.2        -0.26666667  0.93333333 -1.26666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RAVLT Immediate normalize\n",
        "print(\"Before:\", baseline_df_cleaned['RAVLT_immediate'].unique())\n",
        "basic_normalize('RAVLT_immediate')\n",
        "print(\"After:\", baseline_df_cleaned['RAVLT_immediate'])\n"
      ],
      "metadata": {
        "id": "Kh9pX9PeIzYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9743b5f-a5be-4d98-ebc4-d37cbdb976dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: [44. 22. 37. 30. 17. 20. 45. 50. 40. 53. 42. 15. 27. 29. 61. 24. 41. 26.\n",
            " 48. 47. 36. 32. 34. 49. 33. 18. 23. 57. 25. 54. 60. 28. 51. 14. 19. 21.\n",
            " 35. 39. 11. 31. 38. 16. 56. 46. 67. 59. 52. 43. 13. 62. 55. 64. 12.  9.\n",
            " nan 10. 69. 66. 68.  7. 65. 58. 70. 63.  8. 71.  0.  3.  5.  1.]\n",
            "After: 0        0.619718\n",
            "1        0.309859\n",
            "5        0.521127\n",
            "10       0.521127\n",
            "15       0.422535\n",
            "           ...   \n",
            "16237    0.309859\n",
            "16257    0.436620\n",
            "16326    0.633803\n",
            "16338    0.676056\n",
            "16408    0.516504\n",
            "Name: RAVLT_immediate, Length: 2430, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode the diagnosis as has alzheimers/MCI(value of 1) or not (value of 0)\n",
        "dx_dict = {\n",
        "    'CN':0, # normal (no AD)\n",
        "    'Dementia':1, # assume yes AD\n",
        "    'AD':1, # assume yes AD\n",
        "    'MCI':1 # assume yes AD\n",
        "}\n",
        "\n",
        "baseline_df_cleaned['DX'] = baseline_df_cleaned['DX'].replace(dx_dict)\n",
        "\n",
        "# drop nan rows where there isn't a diagnosis\n",
        "baseline_df_cleaned = baseline_df_cleaned.dropna(subset=['DX'])"
      ],
      "metadata": {
        "id": "9VeW0h05I2UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FAQ normalize\n",
        "baseline_df_cleaned['FAQ'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdzkTXHtYBwK",
        "outputId": "c0909962-3cdd-4be9-a1ee-94bb72a6a340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0., 10., 17., 11.,  1.,  2., 12.,  7.,  3.,  9., 29., 20., 28.,\n",
              "        4.,  5., 13.,  8., 22., 24.,  6., 14., 18., 15., 16., 21., 19.,\n",
              "       25., 26., 23., 27., nan, 30.])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Put it all together"
      ],
      "metadata": {
        "id": "aNRp8uqzKYS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keep_cols = ['DX','ABETA', 'TAU', 'PTAU', 'ABETA_bl', 'TAU_bl', 'PTAU_bl',\n",
        "             'PTGENDER', 'PTEDUCAT', 'PTETHCAT','PTRACCAT', 'PTMARRY', 'APOE4',\n",
        "             'FDG', 'PIB', 'AV45','CDRSB', 'AV45', 'CDRSB', 'ADAS11', 'ADAS13',\n",
        "             'MMSE', 'RAVLT_forgetting', 'RAVLT_immediate']\n",
        "baseline_df_all_cleaned = baseline_df_cleaned[keep_cols]\n",
        "\n",
        "# split data into training and test\n",
        "train, test = train_test_split(baseline_df_all_cleaned, random_state=104, test_size=0.30, shuffle=True)\n",
        "\n",
        "# save train and test to csv\n",
        "train.to_csv(r'/content/drive/MyDrive/adnimerge_08Feb2024_cleaned_train_2.csv')\n",
        "test.to_csv(r'/content/drive/MyDrive/adnimerge_08Feb2024_cleaned_test_2.csv')\n",
        "# !mv /content/drive/MyDrive/adnimerge_08Feb2024_cleaned_train_2.csv /content/drive/MyDrive/Data_Science_Alzheimers_ADNI\n",
        "# !mv /content/drive/MyDrive/adnimerge_08Feb2024_cleaned_test_2.csv /content/drive/MyDrive/Data_Science_Alzheimers_ADNI"
      ],
      "metadata": {
        "id": "sqzoH9U_I6hc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d33392-466a-48be-84fc-04dcb7ab3ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'adnimerge_08Feb2024_cleaned_train_2.csv': No such file or directory\n",
            "mv: cannot stat 'adnimerge_08Feb2024_cleaned_test_2.csv': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-uGsh68uC8jz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}